{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import subprocess\n",
    "\n",
    "func_dict = {\"mean\": np.mean, \n",
    "             \"q2.5\": lambda x: np.percentile(x, 2.5), \n",
    "             \"q97.5\": lambda x: np.percentile(x, 97.5)}\n",
    "\n",
    "\n",
    "output_dir = \"../../results/Scenario-1/sens_CUTOFF_TIME\"\n",
    "#!rm -rf {output_dir}\n",
    "!mkdir -p {output_dir}\n",
    "output_data_dir = output_dir + \"/datasets\"\n",
    "!mkdir -p {output_data_dir}\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "class Integrate(theano.Op):\n",
    "    def __init__(self, expr, var, *extra_vars):\n",
    "        super().__init__()\n",
    "        self._expr = expr\n",
    "        self._var = var\n",
    "        self._extra_vars = extra_vars\n",
    "        self._func = theano.function(\n",
    "            [var] + list(extra_vars),\n",
    "            self._expr,\n",
    "            on_unused_input='ignore')\n",
    "    \n",
    "    def make_node(self, start, stop, *extra_vars):\n",
    "        self._extra_vars_node = extra_vars\n",
    "        assert len(self._extra_vars) == len(extra_vars)\n",
    "        self._start = start\n",
    "        self._stop = stop\n",
    "        vars = [start, stop] + list(extra_vars)\n",
    "        return theano.Apply(self, vars, [tt.dscalar().type()])\n",
    "    \n",
    "    def perform(self, node, inputs, out):\n",
    "        start, stop, *args = inputs\n",
    "        val = quad(self._func, start, stop, args=tuple(args))[0]\n",
    "        out[0][0] = np.array(val)\n",
    "        \n",
    "    def grad(self, inputs, grads):\n",
    "        start, stop, *args = inputs\n",
    "        out, = grads\n",
    "        replace = dict(zip(self._extra_vars, args))\n",
    "        \n",
    "        replace_ = replace.copy()\n",
    "        replace_[self._var] = start\n",
    "        dstart = out * theano.clone(-self._expr, replace=replace_)\n",
    "        \n",
    "        replace_ = replace.copy()\n",
    "        replace_[self._var] = stop\n",
    "        dstop = out * theano.clone(self._expr, replace=replace_)\n",
    "\n",
    "        grads = tt.grad(self._expr, self._extra_vars)\n",
    "        dargs = []\n",
    "        for grad in grads:\n",
    "            integrate = Integrate(grad, self._var, *self._extra_vars)\n",
    "            darg = out * integrate(start, stop, *args)\n",
    "            dargs.append(darg)\n",
    "            \n",
    "        return [dstart, dstop] + dargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 34.774:   5%|▌         | 10620/200000 [00:02<00:43, 4311.23it/s]\n",
      "Convergence achieved at 10800\n",
      "Interrupted at 10,799 [5%]: Average Loss = 72.242\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences: 100%|██████████| 125000/125000 [00:36<00:00, 3385.50draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 62.01:   5%|▍         | 9887/200000 [01:10<22:41, 139.68it/s]     \n",
      "Convergence achieved at 9900\n",
      "Interrupted at 9,899 [4%]: Average Loss = 1.466e+07\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [neglogq, neglogr]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 65000/65000 [17:04<00:00, 63.45draws/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 40.797:   5%|▌         | 10098/200000 [00:02<00:48, 3876.25it/s]\n",
      "Convergence achieved at 10300\n",
      "Interrupted at 10,299 [5%]: Average Loss = 79.052\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences: 100%|██████████| 125000/125000 [00:37<00:00, 3341.10draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 67.382:   5%|▌         | 10595/200000 [01:15<22:27, 140.53it/s]   \n",
      "Convergence achieved at 10600\n",
      "Interrupted at 10,599 [5%]: Average Loss = 1.2693e+08\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [neglogq, neglogr]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 65000/65000 [18:19<00:00, 59.13draws/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 46.165:   5%|▌         | 10564/200000 [00:02<00:49, 3816.26it/s]\n",
      "Convergence achieved at 10600\n",
      "Interrupted at 10,599 [5%]: Average Loss = 87.258\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences: 100%|██████████| 125000/125000 [00:37<00:00, 3372.25draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 71.028:   6%|▌         | 11086/200000 [01:18<22:11, 141.91it/s]   \n",
      "Convergence achieved at 11100\n",
      "Interrupted at 11,099 [5%]: Average Loss = 3.0135e+08\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [neglogq, neglogr]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 65000/65000 [20:56<00:00, 51.74draws/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 64.278:   6%|▌         | 11278/200000 [00:03<00:51, 3681.73it/s]\n",
      "Convergence achieved at 11400\n",
      "Interrupted at 11,399 [5%]: Average Loss = 120.92\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences: 100%|██████████| 125000/125000 [00:34<00:00, 3631.70draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 96.801:   6%|▌         | 11295/200000 [01:20<22:21, 140.67it/s]   \n",
      "Convergence achieved at 11300\n",
      "Interrupted at 11,299 [5%]: Average Loss = 2.3773e+08\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [neglogq, neglogr]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 65000/65000 [23:23<00:00, 46.32draws/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 79.165:   5%|▌         | 10120/200000 [00:02<00:50, 3793.13it/s]\n",
      "Convergence achieved at 10200\n",
      "Interrupted at 10,199 [5%]: Average Loss = 147.18\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences: 100%|██████████| 125000/125000 [00:30<00:00, 4057.28draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 114.13:   6%|▌         | 12496/200000 [01:28<22:01, 141.87it/s]   \n",
      "Convergence achieved at 12500\n",
      "Interrupted at 12,499 [6%]: Average Loss = 6.5796e+08\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [neglogq, neglogr]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 65000/65000 [25:55<00:00, 41.80draws/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 86.652:   6%|▌         | 11904/200000 [00:03<00:50, 3692.18it/s]\n",
      "Convergence achieved at 12100\n",
      "Interrupted at 12,099 [6%]: Average Loss = 151.35\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences: 100%|██████████| 125000/125000 [00:30<00:00, 4153.42draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 149.97:   6%|▌         | 11689/200000 [01:22<22:02, 142.36it/s]   \n",
      "Convergence achieved at 11700\n",
      "Interrupted at 11,699 [5%]: Average Loss = 1.0131e+10\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [neglogq, neglogr]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 65000/65000 [33:18<00:00, 32.53draws/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 122.92:   6%|▌         | 12309/200000 [00:03<00:51, 3623.39it/s]\n",
      "Convergence achieved at 12500\n",
      "Interrupted at 12,499 [6%]: Average Loss = 209.66\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences: 100%|██████████| 125000/125000 [00:29<00:00, 4268.84draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 814.28:   5%|▍         | 9890/200000 [01:09<22:22, 141.58it/s]    \n",
      "Convergence achieved at 9900\n",
      "Interrupted at 9,899 [4%]: Average Loss = 4.4964e+09\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [neglogq, neglogr]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 65000/65000 [46:42<00:00, 23.19draws/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 155.97:   6%|▌         | 11924/200000 [00:03<00:49, 3783.83it/s]\n",
      "Convergence achieved at 12000\n",
      "Interrupted at 11,999 [5%]: Average Loss = 261.21\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences: 100%|██████████| 125000/125000 [00:29<00:00, 4303.68draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 424.1:   6%|▌         | 11494/200000 [01:20<22:03, 142.44it/s]    \n",
      "Convergence achieved at 11500\n",
      "Interrupted at 11,499 [5%]: Average Loss = 2.2498e+09\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [neglogq, neglogr]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 65000/65000 [50:59<00:00, 21.25draws/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 170.39:   7%|▋         | 13249/200000 [00:03<00:50, 3680.66it/s]\n",
      "Convergence achieved at 13400\n",
      "Interrupted at 13,399 [6%]: Average Loss = 280.4\n",
      "Multiprocess sampling (5 chains in 5 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 5 chains, 0 divergences:  96%|█████████▌| 120193/125000 [00:26<00:01, 4516.06draws/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The number of samples is too small to check convergence reliably.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_convergence_checks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/backends/report.py\u001b[0m in \u001b[0;36m_run_convergence_checks\u001b[0;34m(self, trace, model)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvarnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvarnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mwarnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/stats/__init__.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 )\n\u001b[1;32m     23\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/stats/diagnostics.py\u001b[0m in \u001b[0;36mrhat\u001b[0;34m(data, var_names, method)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"posterior\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0mvar_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_var_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/converters.py\u001b[0m in \u001b[0;36mconvert_to_dataset\u001b[0;34m(obj, group, coords, dims)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0minference_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_inference_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/converters.py\u001b[0m in \u001b[0;36mconvert_to_inference_data\u001b[0;34m(obj, group, coords, dims, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_pystan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"MultiTrace\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# ugly, but doesn't make PyMC3 a requirement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_pymc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EnsembleSampler\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# ugly, but doesn't make emcee a requirement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_emcee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/io_pymc3.py\u001b[0m in \u001b[0;36mfrom_pymc3\u001b[0;34m(trace, prior, posterior_predictive, coords, dims, model)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mcoords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     ).to_inference_data()\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/io_pymc3.py\u001b[0m in \u001b[0;36mto_inference_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m             **{\n\u001b[1;32m    271\u001b[0m                 \u001b[0;34m\"posterior\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_to_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0;34m\"sample_stats\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_stats_to_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0;34m\"posterior_predictive\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_predictive_to_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_to_xarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/base.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprop_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/io_pymc3.py\u001b[0m in \u001b[0;36msample_stats_to_xarray\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sampler_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlog_likelihood\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log_likelihood\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/base.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprop_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/base.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprop_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/io_pymc3.py\u001b[0m in \u001b[0;36m_extract_log_likelihood\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mchain_likelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mlog_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlog_likelihood_vals_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mchain_likelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain_likelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/io_pymc3.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mchain_likelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mlog_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlog_likelihood_vals_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mchain_likelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain_likelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/arviz/data/io_pymc3.py\u001b[0m in \u001b[0;36mlog_likelihood_vals_point\u001b[0;34m(point)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mlog_like_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_like\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mlog_like_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_de\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mlog_like_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_like_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m         \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/model.py\u001b[0m in \u001b[0;36mPoint\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         raise TypeError(\n\u001b[1;32m   1257\u001b[0m             \"can't turn {} and {} into a dict. {}\".format(args, kwargs, e))\n\u001b[0;32m-> 1258\u001b[0;31m     return dict((str(k), np.array(v)) for k, v in d.items()\n\u001b[0m\u001b[1;32m   1259\u001b[0m                 if str(k) in map(str, model.vars))\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pymc3/model.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \"can't turn {} and {} into a dict. {}\".format(args, kwargs, e))\n\u001b[1;32m   1258\u001b[0m     return dict((str(k), np.array(v)) for k, v in d.items()\n\u001b[0;32m-> 1259\u001b[0;31m                 if str(k) in map(str, model.vars))\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/graph.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \"\"\"\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!rm -rf data_tmp_CUTOFF_TIME\n",
    "!mkdir -p data_tmp_CUTOFF_TIME\n",
    "\n",
    "start = theano.shared(0.)\n",
    "stop = theano.shared(250.)\n",
    "μ = theano.shared(2.838)\n",
    "σ = theano.shared(0.520)\n",
    "\n",
    "for idx, day in enumerate(np.arange(17,26,1)):\n",
    "    t0 = '2019-12-08'\n",
    "    CUTOFF_TIME = '2020-01-%02d'%day\n",
    "    \n",
    "    print(CUTOFF_TIME)\n",
    "    subprocess.call(['Rscript', 'prepare_data.R', './data_tmp_CUTOFF_TIME', t0, CUTOFF_TIME])\n",
    "    \n",
    "    df = pd.read_csv(\"data_tmp_CUTOFF_TIME/data.csv\")\n",
    "    df_onset2death = pd.read_csv(\"data_tmp_CUTOFF_TIME/data_onset2death.csv\")\n",
    "    df_onset2report = pd.read_csv(\"data_tmp_CUTOFF_TIME/data_onset2report.csv\")\n",
    "\n",
    "    for idx0, flnm in enumerate(['data.csv', 'data_onset2death.csv', 'data_onset2report.csv']):\n",
    "        !cp data_tmp_CUTOFF_TIME/{flnm} {output_data_dir}/{CUTOFF_TIME}_{flnm}\n",
    "            \n",
    "    # module for onset2report\n",
    "    with pm.Model() as model_reporting_delay:\n",
    "        a_delay = pm.HalfNormal('a_delay', sd=5)\n",
    "        b_delay = pm.HalfCauchy('b_delay', 2.5)\n",
    "        timeOnsetToDeath = df_onset2report.dist.values\n",
    "        pm.Gamma('likelihood_delay', a_delay, b_delay, observed=timeOnsetToDeath)\n",
    "        pm.Deterministic('mean_delay', a_delay/b_delay);\n",
    "        pm.Deterministic('sd_delay', np.sqrt(a_delay)/b_delay);\n",
    "        trace_reporting_delay = pm.sample(20000, tune=5000, cores=5, target_accept=.85, init='advi')\n",
    "\n",
    "    res_delay = pm.summary(trace_reporting_delay, var_names=['a_delay', 'b_delay', 'mean_delay'])['mean']\n",
    "    df_res = az.summary(trace_reporting_delay, var_names=['mean_delay', 'sd_delay', 'a_delay', 'b_delay'], stat_funcs=func_dict, extend=False, round_to=5).reset_index().rename(columns={'index': 'var'})\n",
    "    df_res.rename(columns={'q2.5': 'lower', 'q97.5': 'upper'}).loc[:,['var','mean','lower','upper']].\\\n",
    "        to_csv(output_dir+'/'+CUTOFF_TIME+'_onset2report.csv', index=False)\n",
    "\n",
    "    # main module\n",
    "    inci_idx = np.min(df.loc[lambda d: d.exports>0].index)\n",
    "    inci_tmin = df.loc[inci_idx,'time']\n",
    "    len_p = len(df.loc[lambda d: d['time']>=inci_tmin,'prob_travel'])\n",
    "    death_idx = np.min(df.loc[lambda d: d['deaths']>0].index)\n",
    "    with pm.Model() as model:  \n",
    "        ## main data and priors ##\n",
    "        K = df['exports'].shape[0]\n",
    "        exported_cases = df['exports'].values\n",
    "        p = df.loc[0,'prob_travel']\n",
    "\n",
    "        neglogr = pm.HalfNormal('neglogr', testval=-np.log(0.1))\n",
    "        r = pm.Deterministic('r',np.exp(-neglogr))\n",
    "        i0 = 1.0\n",
    "\n",
    "        t = tt.arange(1,K+1,1)\n",
    "        Incidence = pm.Deterministic('Incidence',i0*(np.exp(r*t)-1.0)/r)\n",
    "\n",
    "        ## implementing numerical integration \n",
    "        s = tt.dscalar('s')\n",
    "        s.tag.test_value = np.zeros(()) #variable of integration\n",
    "        r_ = tt.dscalar('r_')\n",
    "        r_.tag.test_value = np.ones(())*0.14\n",
    "        func = tt.exp(-r_*s)/s/σ/((2.0*np.pi)**0.5)*tt.exp(-((tt.log(s)-μ)**2)/2/(σ**2))\n",
    "        integrate = Integrate(func, s, r_)\n",
    "\n",
    "        ## calculating us ##\n",
    "        u_delay = pm.Deterministic('u_delay', (1 + r*res_delay['mean_delay']/res_delay['a_delay'])**(-res_delay['a_delay']))\n",
    "        u_death = pm.Deterministic('u_death', integrate(start, stop, r))\n",
    "        ##############################\n",
    "\n",
    "        ## reconstructed incidence from exportation events ##\n",
    "        mu = (u_delay*Incidence*p/(1-p))[inci_idx:K]\n",
    "        alpha = (1.0/(1-p))\n",
    "        pm.Gamma('likelihood_incidence', mu, alpha, shape=K-death_idx, observed=exported_cases[inci_idx:K])\n",
    "        ##############################\n",
    "\n",
    "        ## CFR ##\n",
    "        death = df['deaths'].values\n",
    "        neglogq = pm.Gamma('neglogq', 2, .5, shape=K-death_idx, testval=-np.log(.06))\n",
    "        q = pm.Deterministic('q',np.exp(-neglogq))\n",
    "\n",
    "        shape_death = u_death*Incidence[death_idx:K]*q/(1-q)\n",
    "        invscale_death = 1.0/(1-q)\n",
    "        pm.Gamma('likelihood_death', shape_death, invscale_death, observed=death[death_idx:K])\n",
    "        ##############################\n",
    "\n",
    "        pm.Deterministic('predictedDeath', u_death*Incidence[death_idx:K]*q)\n",
    "\n",
    "        sample = pm.sample(4000, cores=10, tune=2500, target_accept=.92, init='advi')\n",
    "\n",
    "    df_res = az.summary(sample, \n",
    "                        var_names=['r','Incidence','q','u_delay','predictedDeath'], \n",
    "                        stat_funcs=func_dict, extend=False, round_to=6).reset_index().rename(columns={'index': 'var'})\n",
    "    df_res['time'] = df_res['var'].apply(lambda st: st[st.find(\"[\")+1:st.find(\"]\")])\n",
    "    df_res['time'] = ['NA' if \"[\" not in y else int(x)+1 for x,y in zip(df_res['time'],df_res['var'])]\n",
    "    df_res['var'] = df_res['var'].apply(lambda st: st[:st.find(\"[\")] if \"[\" in st else st)\n",
    "    df_res.loc[lambda d: d['var']=='q', 'var'] = 'CFR'\n",
    "    df_res.rename(columns={'q2.5': 'lower', 'q97.5': 'upper'}).loc[:,['var','time','mean','lower','upper']].\\\n",
    "        to_csv(output_dir+'/'+CUTOFF_TIME+'_incidence.csv', index=False)\n",
    "    \n",
    "!rm -rf data_tmp_CUTOFF_TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Was interrupted at the end because 2020-01-25 was not used in the manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
