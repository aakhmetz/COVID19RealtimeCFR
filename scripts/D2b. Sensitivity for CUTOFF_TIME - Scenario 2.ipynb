{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import subprocess\n",
    "\n",
    "func_dict = {\"mean\": np.mean, \n",
    "             \"q2.5\": lambda x: np.percentile(x, 2.5), \n",
    "             \"q97.5\": lambda x: np.percentile(x, 97.5)}\n",
    "\n",
    "output_dir = \"../../results/Scenario-2/sens_CUTOFF_TIME\"\n",
    "!rm -rf {output_dir}\n",
    "!mkdir -p {output_dir}\n",
    "output_data_dir = output_dir + \"/datasets\"\n",
    "!mkdir -p {output_data_dir}\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "class Integrate(theano.Op):\n",
    "    def __init__(self, expr, var, *extra_vars):\n",
    "        super().__init__()\n",
    "        self._expr = expr\n",
    "        self._var = var\n",
    "        self._extra_vars = extra_vars\n",
    "        self._func = theano.function(\n",
    "            [var] + list(extra_vars),\n",
    "            self._expr,\n",
    "            on_unused_input='ignore')\n",
    "    \n",
    "    def make_node(self, start, stop, *extra_vars):\n",
    "        self._extra_vars_node = extra_vars\n",
    "        assert len(self._extra_vars) == len(extra_vars)\n",
    "        self._start = start\n",
    "        self._stop = stop\n",
    "        vars = [start, stop] + list(extra_vars)\n",
    "        return theano.Apply(self, vars, [tt.dscalar().type()])\n",
    "    \n",
    "    def perform(self, node, inputs, out):\n",
    "        start, stop, *args = inputs\n",
    "        val = quad(self._func, start, stop, args=tuple(args))[0]\n",
    "        out[0][0] = np.array(val)\n",
    "        \n",
    "    def grad(self, inputs, grads):\n",
    "        start, stop, *args = inputs\n",
    "        out, = grads\n",
    "        replace = dict(zip(self._extra_vars, args))\n",
    "        \n",
    "        replace_ = replace.copy()\n",
    "        replace_[self._var] = start\n",
    "        dstart = out * theano.clone(-self._expr, replace=replace_)\n",
    "        \n",
    "        replace_ = replace.copy()\n",
    "        replace_[self._var] = stop\n",
    "        dstop = out * theano.clone(self._expr, replace=replace_)\n",
    "\n",
    "        grads = tt.grad(self._expr, self._extra_vars)\n",
    "        dargs = []\n",
    "        for grad in grads:\n",
    "            integrate = Integrate(grad, self._var, *self._extra_vars)\n",
    "            darg = out * integrate(start, stop, *args)\n",
    "            dargs.append(darg)\n",
    "            \n",
    "        return [dstart, dstop] + dargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 34.808:   5%|▌         | 10551/200000 [00:02<00:46, 4050.72it/s]\n",
      "Convergence achieved at 10900\n",
      "Interrupted at 10,899 [5%]: Average Loss = 72.071\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 150000/150000 [00:37<00:00, 4000.58draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 8.3814e+19:   0%|          | 885/200000 [00:05<21:08, 157.01it/s]\n",
      "Convergence achieved at 900\n",
      "Interrupted at 899 [0%]: Average Loss = 2.6677e+15\n",
      "Multiprocess sampling (8 chains in 8 jobs)\n",
      "NUTS: [neglogq, logi0, neglogr]\n",
      "Sampling 8 chains, 0 divergences: 100%|██████████| 54000/54000 [1:05:12<00:00, 13.80draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 40.436:   5%|▌         | 10071/200000 [00:02<00:51, 3714.52it/s]\n",
      "Convergence achieved at 10500\n",
      "Interrupted at 10,499 [5%]: Average Loss = 78.796\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 150000/150000 [00:36<00:00, 4081.52draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 4,316.2:   5%|▌         | 10886/200000 [01:07<19:29, 161.73it/s]  \n",
      "Convergence achieved at 10900\n",
      "Interrupted at 10,899 [5%]: Average Loss = 8.6218e+18\n",
      "Multiprocess sampling (8 chains in 8 jobs)\n",
      "NUTS: [neglogq, logi0, neglogr]\n",
      "Sampling 8 chains, 0 divergences: 100%|██████████| 54000/54000 [50:38<00:00, 17.77draws/s]  \n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 47.75:   5%|▍         | 9521/200000 [00:01<00:35, 5333.07it/s] \n",
      "Convergence achieved at 9800\n",
      "Interrupted at 9,799 [4%]: Average Loss = 92.103\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 150000/150000 [00:35<00:00, 4264.20draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 7.5218e+18:   0%|          | 885/200000 [00:05<18:51, 176.04it/s]\n",
      "Convergence achieved at 900\n",
      "Interrupted at 899 [0%]: Average Loss = 9.6799e+10\n",
      "Multiprocess sampling (8 chains in 8 jobs)\n",
      "NUTS: [neglogq, logi0, neglogr]\n",
      "Sampling 8 chains, 0 divergences: 100%|██████████| 54000/54000 [1:02:14<00:00, 14.46draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 64.657:   6%|▌         | 11033/200000 [00:02<00:35, 5333.80it/s]\n",
      "Convergence achieved at 11100\n",
      "Interrupted at 11,099 [5%]: Average Loss = 122.89\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 150000/150000 [00:38<00:00, 3852.29draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 605.91:   4%|▍         | 8695/200000 [00:55<20:19, 156.90it/s]    \n",
      "Convergence achieved at 8700\n",
      "Interrupted at 8,699 [4%]: Average Loss = 9.2752e+19\n",
      "Multiprocess sampling (8 chains in 8 jobs)\n",
      "NUTS: [neglogq, logi0, neglogr]\n",
      "Sampling 8 chains, 0 divergences: 100%|██████████| 54000/54000 [53:27<00:00, 16.84draws/s]  \n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 77.121:   6%|▌         | 11131/200000 [00:02<00:40, 4677.22it/s]\n",
      "Convergence achieved at 11200\n",
      "Interrupted at 11,199 [5%]: Average Loss = 140.43\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 150000/150000 [00:35<00:00, 4213.68draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 384.8:   4%|▍         | 8997/200000 [00:56<19:51, 160.31it/s]     \n",
      "Convergence achieved at 9000\n",
      "Interrupted at 8,999 [4%]: Average Loss = 2.7535e+23\n",
      "Multiprocess sampling (8 chains in 8 jobs)\n",
      "NUTS: [neglogq, logi0, neglogr]\n",
      "Sampling 8 chains, 0 divergences: 100%|██████████| 54000/54000 [59:55<00:00, 15.02draws/s]  \n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 89.923:   5%|▍         | 9958/200000 [00:02<00:49, 3838.87it/s]\n",
      "Convergence achieved at 10400\n",
      "Interrupted at 10,399 [5%]: Average Loss = 162\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 150000/150000 [00:36<00:00, 4117.95draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 5.3653e+23:   0%|          | 396/200000 [00:02<21:10, 157.14it/s]\n",
      "Convergence achieved at 400\n",
      "Interrupted at 399 [0%]: Average Loss = 5.2577e+23\n",
      "Multiprocess sampling (8 chains in 8 jobs)\n",
      "NUTS: [neglogq, logi0, neglogr]\n",
      "Sampling 8 chains, 0 divergences: 100%|██████████| 54000/54000 [1:20:47<00:00, 11.14draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 125.08:   6%|▌         | 11378/200000 [00:03<00:49, 3787.71it/s]\n",
      "Convergence achieved at 11700\n",
      "Interrupted at 11,699 [5%]: Average Loss = 208.58\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 150000/150000 [00:34<00:00, 4336.66draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 1.9997e+05:   3%|▎         | 6399/200000 [00:39<19:43, 163.64it/s]\n",
      "Convergence achieved at 6400\n",
      "Interrupted at 6,399 [3%]: Average Loss = 5.8387e+15\n",
      "Multiprocess sampling (8 chains in 8 jobs)\n",
      "NUTS: [neglogq, logi0, neglogr]\n",
      "Sampling 8 chains, 0 divergences: 100%|██████████| 54000/54000 [1:19:41<00:00, 11.29draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 153.39:   6%|▋         | 12521/200000 [00:02<00:34, 5437.61it/s]\n",
      "Convergence achieved at 12700\n",
      "Interrupted at 12,699 [6%]: Average Loss = 256.24\n",
      "Multiprocess sampling (10 chains in 10 jobs)\n",
      "NUTS: [b_delay, a_delay]\n",
      "Sampling 10 chains, 0 divergences: 100%|██████████| 150000/150000 [00:32<00:00, 4555.72draws/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 1.418e+09:   2%|▏         | 4782/200000 [00:27<18:32, 175.52it/s] \n",
      "Convergence achieved at 4800\n",
      "Interrupted at 4,799 [2%]: Average Loss = 5.407e+19\n",
      "Multiprocess sampling (8 chains in 8 jobs)\n",
      "NUTS: [neglogq, logi0, neglogr]\n",
      "Sampling 8 chains, 0 divergences:  24%|██▎       | 12820/54000 [23:15<1:14:42,  9.19draws/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, **kwargs)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m                     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mpipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_msg_pipe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, **kwargs)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         \u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_choose_chains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_choose_chains\u001b[0;34m(traces, tune)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not enough samples to build a trace.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!rm -rf data_tmp_CUTOFF_TIME_2\n",
    "!mkdir -p data_tmp_CUTOFF_TIME_2\n",
    "\n",
    "start = theano.shared(0.)\n",
    "stop = theano.shared(250.)\n",
    "μ = theano.shared(2.838)\n",
    "σ = theano.shared(0.520)\n",
    "\n",
    "for idx, day in enumerate(np.arange(17,26,1)):\n",
    "    t0 = '2019-12-08'\n",
    "    CUTOFF_TIME = '2020-01-%02d'%day\n",
    "    \n",
    "    print(CUTOFF_TIME)\n",
    "    subprocess.call(['Rscript', 'prepare_data.R', './data_tmp_CUTOFF_TIME_2', t0, CUTOFF_TIME])\n",
    "    \n",
    "    df = pd.read_csv(\"data_tmp_CUTOFF_TIME_2/data.csv\")\n",
    "    df_onset2death = pd.read_csv(\"data_tmp_CUTOFF_TIME_2/data_onset2death.csv\")\n",
    "    df_onset2report = pd.read_csv(\"data_tmp_CUTOFF_TIME_2/data_onset2report.csv\")\n",
    "\n",
    "    for idx0, flnm in enumerate(['data.csv', 'data_onset2death.csv', 'data_onset2report.csv']):\n",
    "        !cp data_tmp_CUTOFF_TIME_2/{flnm} {output_data_dir}/{CUTOFF_TIME}_{flnm}\n",
    "            \n",
    "    # module for onset2report\n",
    "    with pm.Model() as model_reporting_delay:\n",
    "        a_delay = pm.HalfNormal('a_delay', sd=5)\n",
    "        b_delay = pm.HalfCauchy('b_delay', 2.5)\n",
    "        timeOnsetToDeath = df_onset2report.dist.values\n",
    "        pm.Gamma('likelihood_delay', a_delay, b_delay, observed=timeOnsetToDeath)\n",
    "        pm.Deterministic('mean_delay', a_delay/b_delay);\n",
    "        pm.Deterministic('sd_delay', np.sqrt(a_delay)/b_delay);\n",
    "        trace_reporting_delay = pm.sample(10000, tune=5000, cores=10, target_accept=.85, init='advi')\n",
    "\n",
    "    res_delay = pm.summary(trace_reporting_delay, var_names=['a_delay', 'b_delay', 'mean_delay'])['mean']\n",
    "    df_res = az.summary(trace_reporting_delay, var_names=['mean_delay', 'sd_delay', 'a_delay', 'b_delay'], stat_funcs=func_dict, extend=False, round_to=5).reset_index().rename(columns={'index': 'var'})\n",
    "    df_res.rename(columns={'q2.5': 'lower', 'q97.5': 'upper'}).loc[:,['var','mean','lower','upper']].\\\n",
    "        to_csv(output_dir+'/'+CUTOFF_TIME+'_onset2report.csv', index=False)\n",
    "\n",
    "    # main module\n",
    "    inci_idx = np.min(df.loc[lambda d: d.exports>0].index)\n",
    "    inci_tmin = df.loc[inci_idx,'time']\n",
    "    len_p = len(df.loc[lambda d: d['time']>=inci_tmin,'prob_travel'])\n",
    "    death_idx = np.min(df.loc[lambda d: d['deaths']>0].index)\n",
    "    T0 = df['time'].values[inci_idx]\n",
    "    with pm.Model() as model:  \n",
    "        ## main data and priors ##\n",
    "        K = df['exports'].shape[0]\n",
    "        exported_cases = df['exports'].values\n",
    "        p = df.loc[0,'prob_travel']\n",
    "\n",
    "        neglogr = pm.HalfNormal('neglogr', testval=-np.log(0.1))\n",
    "        r = pm.Deterministic('r',np.exp(-neglogr))\n",
    "        logi0 = pm.HalfNormal('logi0', sd=np.log(1000), testval=np.log(500))\n",
    "        i0 = pm.Deterministic('i0', tt.exp(logi0))\n",
    "\n",
    "        t = tt.arange(1,K+1,1)\n",
    "        Incidence = pm.Deterministic('Incidence',i0*(tt.exp(r*(t-T0))-tt.exp(-r*T0))/r)\n",
    "\n",
    "        ## implementing numerical integration \n",
    "        s = tt.dscalar('s')\n",
    "        s.tag.test_value = np.zeros(()) #variable of integration\n",
    "        r_ = tt.dscalar('r_')\n",
    "        r_.tag.test_value = np.ones(())*0.14\n",
    "        func = tt.exp(-r_*s)/s/σ/((2.0*np.pi)**0.5)*tt.exp(-((tt.log(s)-μ)**2)/2/(σ**2))\n",
    "        integrate = Integrate(func, s, r_)\n",
    "\n",
    "        ## calculating us ##\n",
    "        u_delay = pm.Deterministic('u_delay', (1 + r*res_delay['mean_delay']/res_delay['a_delay'])**(-res_delay['a_delay']))\n",
    "        u_death = pm.Deterministic('u_death', integrate(start, stop, r))\n",
    "        ##############################\n",
    "\n",
    "        ## reconstructed incidence from exportation events ##\n",
    "        mu = (u_delay*Incidence*p/(1-p))[inci_idx:K]\n",
    "        alpha = (1.0/(1-p))\n",
    "        pm.Gamma('likelihood_incidence', mu, alpha, shape=K-inci_idx, \n",
    "                 observed=exported_cases[inci_idx:K])\n",
    "        ##############################\n",
    "\n",
    "        ## CFR ##\n",
    "        death = df['deaths'].values\n",
    "        neglogq = pm.Gamma('neglogq', 2, .5, shape=K-death_idx, testval=-np.log(.06))\n",
    "        q = pm.Deterministic('q',np.exp(-neglogq))\n",
    "\n",
    "        shape_death = u_death*Incidence[death_idx:K]*q/(1-q)\n",
    "        invscale_death = 1.0/(1-q)\n",
    "        pm.Gamma('likelihood_death', shape_death, invscale_death, observed=death[death_idx:K])\n",
    "        ##############################\n",
    "\n",
    "        pm.Deterministic('predictedDeath', u_death*Incidence[death_idx:K]*q)\n",
    "\n",
    "        sample = pm.sample(4250, cores=8, tune=2500, target_accept=.92, init='advi')\n",
    "\n",
    "    df_res = az.summary(sample, \n",
    "                        var_names=['r','Incidence','q','u_delay','u_death', 'predictedDeath'], \n",
    "                        stat_funcs=func_dict, extend=False, round_to=6).reset_index().rename(columns={'index': 'var'})\n",
    "    df_res['time'] = df_res['var'].apply(lambda st: st[st.find(\"[\")+1:st.find(\"]\")])\n",
    "    df_res['time'] = ['NA' if \"[\" not in y else int(x)+1 for x,y in zip(df_res['time'],df_res['var'])]\n",
    "    df_res['var'] = df_res['var'].apply(lambda st: st[:st.find(\"[\")] if \"[\" in st else st)\n",
    "    df_res.loc[lambda d: d['var']=='q', 'var'] = 'CFR'\n",
    "    df_res.rename(columns={'q2.5': 'lower', 'q97.5': 'upper'}).loc[:,['var','time','mean','lower','upper']].\\\n",
    "        to_csv(output_dir+'/'+CUTOFF_TIME+'_incidence.csv', index=False)\n",
    "    \n",
    "!rm -rf data_tmp_CUTOFF_TIME_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Was interrupted at the end because 2020-01-25 was not used in the manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
